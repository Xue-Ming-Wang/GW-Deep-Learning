{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14521e33-249c-45b7-88d4-5729e3fb3f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1298c69d-b109-4c22-84c0-43ee56d143e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_path = \"/Users/vivianwang/Desktop/data2.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce73860-fe0b-40c6-9283-73eda7bb4d07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>WordEmbeddings_input</th>\n",
       "      <th>WordEmbeddings_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['woke', 'morn', 'feel', 'whole', 'room', 'spi...</td>\n",
       "      <td>['hi', 'thank', 'post', 'queri', 'like', 'caus...</td>\n",
       "      <td>[-0.0619953  -0.6736265   0.27994376 -0.085758...</td>\n",
       "      <td>[-0.18782409 -0.88191456  0.14123142  0.173059...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['babi', 'poo', 'time', 'day', 'week', 'last',...</td>\n",
       "      <td>['hi', 'thank', 'consult', 'chat', 'doctor', '...</td>\n",
       "      <td>[ 0.31923333 -0.6726571  -0.16014402 -0.239708...</td>\n",
       "      <td>[-0.11867172 -0.927781    0.11605667  0.053519...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['hello', 'husband', 'take', 'oxycodon', 'due'...</td>\n",
       "      <td>['hello', 'hope', 'help', 'todayfirst', 'medic...</td>\n",
       "      <td>[ 0.07557318 -0.8664425   0.2868909   0.074551...</td>\n",
       "      <td>[-0.07790519 -0.9422826   0.19836313  0.008373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['lump', 'left', 'nippl', 'stomach', 'pain', '...</td>\n",
       "      <td>['hi', 'two', 'differ', 'problem', 'lump', 'ni...</td>\n",
       "      <td>[ 1.45712122e-01 -7.75916994e-01  1.59821466e-...</td>\n",
       "      <td>[-0.0350829  -0.5795279   0.00846534  0.203456...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['month', 'old', 'babi', 'congest', 'terribl',...</td>\n",
       "      <td>['thank', 'use', 'chat', 'doctor', 'would', 's...</td>\n",
       "      <td>[-0.00440924 -0.8600714   0.1022485   0.140155...</td>\n",
       "      <td>[-0.11640272 -0.8963055   0.17284362  0.040940...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112160</th>\n",
       "      <td>['im', '25', 'year', 'old', 'start', 'use', 'm...</td>\n",
       "      <td>['hello', 'thank', 'let', 'u', 'know', 'health...</td>\n",
       "      <td>[-0.0474515  -0.73382026 -0.0372104   0.085389...</td>\n",
       "      <td>[-0.01673762 -1.057229    0.26074028  0.190503...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112161</th>\n",
       "      <td>['year', 'old', 'son', 'cough', 'month', 'take...</td>\n",
       "      <td>['mention', 'histori', 'son', 'cough', 'sinc',...</td>\n",
       "      <td>[ 0.11159492 -0.9231173   0.00670093 -0.010550...</td>\n",
       "      <td>[-0.14276338 -0.991815    0.02161139  0.257161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112162</th>\n",
       "      <td>['toe', 'right', 'foot', 'left', 'numb', 'turn...</td>\n",
       "      <td>['hi', 'numb', 'blue', 'discolor', 'could', 'd...</td>\n",
       "      <td>[ 0.00540123 -0.5803814   0.22330971  0.105037...</td>\n",
       "      <td>[-0.05790729 -1.046325    0.32568908  0.108866...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112163</th>\n",
       "      <td>['diagnosi', 'pleurisi', 'last', 'tuesday', 's...</td>\n",
       "      <td>['thank', 'question', 'chat', 'doctor', 'treat...</td>\n",
       "      <td>[-1.41046569e-01 -7.67617047e-01  7.36642182e-...</td>\n",
       "      <td>[-0.13445875 -0.8021505   0.33348566  0.051080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112164</th>\n",
       "      <td>['within', 'past', 'hour', 'husband', 'develop...</td>\n",
       "      <td>['hello', 'thank', 'post', 'chat', 'doctor', '...</td>\n",
       "      <td>[ 0.12263802 -0.85153365  0.01135513 -0.147815...</td>\n",
       "      <td>[-0.1515099  -0.7969958   0.20666964  0.058075...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112165 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    input  \\\n",
       "0       ['woke', 'morn', 'feel', 'whole', 'room', 'spi...   \n",
       "1       ['babi', 'poo', 'time', 'day', 'week', 'last',...   \n",
       "2       ['hello', 'husband', 'take', 'oxycodon', 'due'...   \n",
       "3       ['lump', 'left', 'nippl', 'stomach', 'pain', '...   \n",
       "4       ['month', 'old', 'babi', 'congest', 'terribl',...   \n",
       "...                                                   ...   \n",
       "112160  ['im', '25', 'year', 'old', 'start', 'use', 'm...   \n",
       "112161  ['year', 'old', 'son', 'cough', 'month', 'take...   \n",
       "112162  ['toe', 'right', 'foot', 'left', 'numb', 'turn...   \n",
       "112163  ['diagnosi', 'pleurisi', 'last', 'tuesday', 's...   \n",
       "112164  ['within', 'past', 'hour', 'husband', 'develop...   \n",
       "\n",
       "                                                   output  \\\n",
       "0       ['hi', 'thank', 'post', 'queri', 'like', 'caus...   \n",
       "1       ['hi', 'thank', 'consult', 'chat', 'doctor', '...   \n",
       "2       ['hello', 'hope', 'help', 'todayfirst', 'medic...   \n",
       "3       ['hi', 'two', 'differ', 'problem', 'lump', 'ni...   \n",
       "4       ['thank', 'use', 'chat', 'doctor', 'would', 's...   \n",
       "...                                                   ...   \n",
       "112160  ['hello', 'thank', 'let', 'u', 'know', 'health...   \n",
       "112161  ['mention', 'histori', 'son', 'cough', 'sinc',...   \n",
       "112162  ['hi', 'numb', 'blue', 'discolor', 'could', 'd...   \n",
       "112163  ['thank', 'question', 'chat', 'doctor', 'treat...   \n",
       "112164  ['hello', 'thank', 'post', 'chat', 'doctor', '...   \n",
       "\n",
       "                                     WordEmbeddings_input  \\\n",
       "0       [-0.0619953  -0.6736265   0.27994376 -0.085758...   \n",
       "1       [ 0.31923333 -0.6726571  -0.16014402 -0.239708...   \n",
       "2       [ 0.07557318 -0.8664425   0.2868909   0.074551...   \n",
       "3       [ 1.45712122e-01 -7.75916994e-01  1.59821466e-...   \n",
       "4       [-0.00440924 -0.8600714   0.1022485   0.140155...   \n",
       "...                                                   ...   \n",
       "112160  [-0.0474515  -0.73382026 -0.0372104   0.085389...   \n",
       "112161  [ 0.11159492 -0.9231173   0.00670093 -0.010550...   \n",
       "112162  [ 0.00540123 -0.5803814   0.22330971  0.105037...   \n",
       "112163  [-1.41046569e-01 -7.67617047e-01  7.36642182e-...   \n",
       "112164  [ 0.12263802 -0.85153365  0.01135513 -0.147815...   \n",
       "\n",
       "                                    WordEmbeddings_output  \n",
       "0       [-0.18782409 -0.88191456  0.14123142  0.173059...  \n",
       "1       [-0.11867172 -0.927781    0.11605667  0.053519...  \n",
       "2       [-0.07790519 -0.9422826   0.19836313  0.008373...  \n",
       "3       [-0.0350829  -0.5795279   0.00846534  0.203456...  \n",
       "4       [-0.11640272 -0.8963055   0.17284362  0.040940...  \n",
       "...                                                   ...  \n",
       "112160  [-0.01673762 -1.057229    0.26074028  0.190503...  \n",
       "112161  [-0.14276338 -0.991815    0.02161139  0.257161...  \n",
       "112162  [-0.05790729 -1.046325    0.32568908  0.108866...  \n",
       "112163  [-0.13445875 -0.8021505   0.33348566  0.051080...  \n",
       "112164  [-0.1515099  -0.7969958   0.20666964  0.058075...  \n",
       "\n",
       "[112165 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b80315-3b73-4bce-80bc-30eb8b23c2f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 input  \\\n",
      "0    ['woke', 'morn', 'feel', 'whole', 'room', 'spi...   \n",
      "1    ['babi', 'poo', 'time', 'day', 'week', 'last',...   \n",
      "2    ['hello', 'husband', 'take', 'oxycodon', 'due'...   \n",
      "3    ['lump', 'left', 'nippl', 'stomach', 'pain', '...   \n",
      "4    ['month', 'old', 'babi', 'congest', 'terribl',...   \n",
      "..                                                 ...   \n",
      "995  ['fianc', '27', 'yo', 'male', 'knot', 'come', ...   \n",
      "996  ['hi', 'khushboo', '22week', 'scan', 'done', '...   \n",
      "997  ['father', 'suffer', 'vascul', 'three', 'month...   \n",
      "998  ['hello', 'issu', 'bother', 'pain', 'stomach',...   \n",
      "999  ['left', 'side', 'lower', 'rib', 'cage', 'ante...   \n",
      "\n",
      "                                                output  \\\n",
      "0    ['hi', 'thank', 'post', 'queri', 'like', 'caus...   \n",
      "1    ['hi', 'thank', 'consult', 'chat', 'doctor', '...   \n",
      "2    ['hello', 'hope', 'help', 'todayfirst', 'medic...   \n",
      "3    ['hi', 'two', 'differ', 'problem', 'lump', 'ni...   \n",
      "4    ['thank', 'use', 'chat', 'doctor', 'would', 's...   \n",
      "..                                                 ...   \n",
      "995  ['hello', 'alopecia', 'lymphadenopathi', 'may'...   \n",
      "996  ['welcom', 'chat', 'doctor', 'ye', 'left', 'ki...   \n",
      "997  ['hi', 'thank', 'provid', 'brief', 'histori', ...   \n",
      "998  ['hi', 'welcom', 'chat', 'doctor', 'forum', 't...   \n",
      "999  ['hello', 'thank', 'write', 'u', 'studi', 'cas...   \n",
      "\n",
      "                                  WordEmbeddings_input  \\\n",
      "0    [-0.0619953  -0.6736265   0.27994376 -0.085758...   \n",
      "1    [ 0.31923333 -0.6726571  -0.16014402 -0.239708...   \n",
      "2    [ 0.07557318 -0.8664425   0.2868909   0.074551...   \n",
      "3    [ 1.45712122e-01 -7.75916994e-01  1.59821466e-...   \n",
      "4    [-0.00440924 -0.8600714   0.1022485   0.140155...   \n",
      "..                                                 ...   \n",
      "995  [-0.01158299 -0.654199    0.0426545   0.205337...   \n",
      "996  [-0.05035998 -0.82140213  0.2798825   0.415774...   \n",
      "997  [-0.05972387 -0.7746822   0.14126234  0.089905...   \n",
      "998  [-0.00695474 -1.0327587   0.16661064  0.069822...   \n",
      "999  [-0.03493161 -0.73219484  0.18739977  0.261420...   \n",
      "\n",
      "                                 WordEmbeddings_output  \n",
      "0    [-0.18782409 -0.88191456  0.14123142  0.173059...  \n",
      "1    [-0.11867172 -0.927781    0.11605667  0.053519...  \n",
      "2    [-0.07790519 -0.9422826   0.19836313  0.008373...  \n",
      "3    [-0.0350829  -0.5795279   0.00846534  0.203456...  \n",
      "4    [-0.11640272 -0.8963055   0.17284362  0.040940...  \n",
      "..                                                 ...  \n",
      "995  [-0.14813219 -0.9556134   0.16245437  0.153363...  \n",
      "996  [-0.10753805 -0.806457   -0.02335747  0.231667...  \n",
      "997  [ 0.00269563 -0.92788064  0.28851688  0.061969...  \n",
      "998  [-0.04216364 -1.0861489   0.2488215   0.158840...  \n",
      "999  [-0.11814729 -0.8571309   0.26842037  0.219972...  \n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove first 7000 rows\n",
    "df = df.iloc[:1000]\n",
    "\n",
    "# Verify the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccf64d8a-3423-4240-a033-ac655cce43f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 33s 2s/step - loss: 9.0725 - accuracy: 0.5491 - val_loss: 9.0118 - val_accuracy: 0.7217\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 30s 2s/step - loss: 8.7747 - accuracy: 0.7176 - val_loss: 8.3593 - val_accuracy: 0.7217\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 26s 2s/step - loss: 7.9784 - accuracy: 0.7176 - val_loss: 7.4574 - val_accuracy: 0.7217\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 23s 2s/step - loss: 7.0020 - accuracy: 0.7176 - val_loss: 6.4546 - val_accuracy: 0.7217\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 23s 2s/step - loss: 6.0430 - accuracy: 0.7176 - val_loss: 5.5647 - val_accuracy: 0.7217\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 5.2024 - accuracy: 0.7176 - val_loss: 4.7743 - val_accuracy: 0.7217\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 4.4526 - accuracy: 0.7176 - val_loss: 4.0722 - val_accuracy: 0.7217\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 29s 2s/step - loss: 3.8027 - accuracy: 0.7176 - val_loss: 3.4907 - val_accuracy: 0.7217\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 27s 2s/step - loss: 3.2951 - accuracy: 0.7176 - val_loss: 3.0782 - val_accuracy: 0.7217\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 26s 2s/step - loss: 2.9665 - accuracy: 0.7176 - val_loss: 2.8415 - val_accuracy: 0.7217\n",
      "7/7 [==============================] - 4s 609ms/step - loss: 2.8415 - accuracy: 0.7217\n",
      "Test Accuracy: 72.17%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['input'] + df['output'])\n",
    "\n",
    "input_sequences = tokenizer.texts_to_sequences(df['input'])\n",
    "output_sequences = tokenizer.texts_to_sequences(df['output'])\n",
    "\n",
    "max_len = max(max(len(seq) for seq in input_sequences), max(len(seq) for seq in output_sequences))\n",
    "\n",
    "padded_input = pad_sequences(input_sequences, maxlen=max_len, padding='post')\n",
    "padded_output = pad_sequences(output_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_input, padded_output, test_size=0.2, random_state=42)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32, input_length=max_len))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75117d0-728f-4cc9-956f-a414de47017f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
